{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb783e0b",
   "metadata": {},
   "source": [
    "# Projet : Prédiction du Churn Client (Telco)\n",
    "\n",
    "Notebook complet : nettoyage, EDA, modélisation et sauvegarde du modèle.\n",
    "\n",
    "**Remarque :** place le fichier CSV `WA_Fn-UseC_-Telco-Customer-Churn.csv` dans `/mnt/data/data/` ou `./data/` avant d'exécuter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure plots render (in Jupyter)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d4eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (modify path if needed)\n",
    "path = '/mnt/data/data/WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
    "if not os.path.exists(path):\n",
    "    raise FileNotFoundError(f\"Dataset not found at {path}. Place the Telco CSV in that path before running.\")\n",
    "df = pd.read_csv(path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fcd58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc433ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Convert TotalCharges to numeric (coerce errors), strip whitespace\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "# Drop customerID as identifier\n",
    "if 'customerID' in df.columns:\n",
    "    df = df.drop(columns=['customerID'])\n",
    "\n",
    "# Target encode\n",
    "df['Churn'] = df['Churn'].map({'Yes':1, 'No':0})\n",
    "\n",
    "# Identify numerical and categorical\n",
    "num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "if 'Churn' in num_cols:\n",
    "    num_cols.remove('Churn')\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print('Numerical cols:', num_cols)\n",
    "print('Categorical cols:', cat_cols)\n",
    "\n",
    "# Impute numeric and encode categorical\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# For categorical encoding we'll use one-hot for simplicity\n",
    "df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
    "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n",
    "\n",
    "# One-hot encode categorical\n",
    "df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Final feature/target split\n",
    "X = df.drop(columns=['Churn'])\n",
    "y = df['Churn']\n",
    "print('X shape:', X.shape, 'y distribution:', y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1902164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA - Distribution and simple plots using matplotlib\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(y, bins=2)\n",
    "plt.title('Distribution of Churn (0 = No, 1 = Yes)')\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Tenure vs Churn - mean churn by tenure bucket\n",
    "df_temp = df.copy()\n",
    "if 'tenure' in df_temp.columns:\n",
    "    tenure = df_temp['tenure']\n",
    "    bins = [0,3,6,12,24,48,72]\n",
    "    df_temp['tenure_bin'] = pd.cut(tenure, bins=bins)\n",
    "    churn_by_tenure = df_temp.groupby('tenure_bin')['Churn'].mean()\n",
    "    churn_by_tenure.plot(kind='bar')\n",
    "    plt.title('Churn rate by tenure bins')\n",
    "    plt.xlabel('Tenure bin')\n",
    "    plt.ylabel('Churn rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling - train/test split and baseline models\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Standardize numeric columns indices (approximate by checking dtype)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Baseline Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "print('Logistic Regression - Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print('Random Forest - Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c4d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for Random Forest (GridSearchCV)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "gsearch = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "gsearch.fit(X_train, y_train)\n",
    "print('Best params:', gsearch.best_params_)\n",
    "best_rf = gsearch.best_estimator_\n",
    "y_pred_best = best_rf.predict(X_test)\n",
    "print('Tuned RF - Accuracy:', accuracy_score(y_test, y_pred_best))\n",
    "print('Tuned RF - F1:', f1_score(y_test, y_pred_best))\n",
    "print('ROC AUC:', roc_auc_score(y_test, best_rf.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and scaler\n",
    "out_model_path = '/mnt/data/project_churn_output/best_model.joblib'\n",
    "out_scaler_path = '/mnt/data/project_churn_output/scaler.joblib'\n",
    "joblib.dump(best_rf, out_model_path)\n",
    "joblib.dump(scaler, out_scaler_path)\n",
    "print('Saved model to', out_model_path)\n",
    "print('Saved scaler to', out_scaler_path)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
